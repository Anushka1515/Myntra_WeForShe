{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "juLBh1l7uuDi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset without locations"
      ],
      "metadata": {
        "id": "247zVSX_5Gm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('styles.csv',on_bad_lines='skip')"
      ],
      "metadata": {
        "id": "OD6_W11WuwdO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding locations"
      ],
      "metadata": {
        "id": "Q4t04B4S5KSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "locations = ['Delhi', 'Mumbai', 'Bangalore', 'Kolkata', 'Chennai', 'Hyderabad',\n",
        "             'Jaipur', 'Lucknow', 'Ahmedabad', 'Srinagar', 'Goa', 'Kochi',\n",
        "             'Guwahati', 'Bhopal', 'Shimla']\n",
        "\n",
        "# Create a function to determine location based on row values\n",
        "def determine_location(row):\n",
        "    # Example heuristic: combine certain columns to create an index\n",
        "    index = (hash(row['gender']) + hash(row['masterCategory']) +\n",
        "             hash(row['subCategory']) + hash(row['articleType']) +\n",
        "             hash(row['baseColour']) + hash(row['season']) +\n",
        "             hash(row['year']) + hash(row['usage'])) % len(locations)\n",
        "    return locations[index]\n",
        "\n",
        "# Apply the function to each row\n",
        "df['location'] = df.apply(determine_location, axis=1)"
      ],
      "metadata": {
        "id": "9Lu_u0oiuz2K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding fabric and fit"
      ],
      "metadata": {
        "id": "93YWrA5P5NR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fabric_options = {\n",
        "    'Jeans': ['denim', 'cotton', 'polyester', 'blend', 'corduroy', 'canvas'],\n",
        "    'Kurtas': ['cotton', 'silk', 'linen', 'khadi', 'rayon', 'wool'],\n",
        "    'Tshirts': ['cotton', 'polyester', 'nylon', 'spandex', 'viscose', 'modal'],\n",
        "    'Shirts': ['cotton', 'polyester', 'nylon', 'spandex', 'viscose', 'modal'],\n",
        "    'Sweatshirts': ['fleece', 'cotton', 'polyester', 'wool', 'blend', 'cashmere'],\n",
        "    'Shorts': ['nylon', 'cotton', 'polyester', 'spandex', 'linen', 'silk'],\n",
        "    'Track Pants': ['cotton', 'polyester', 'nylon', 'blend', 'fleece', 'spandex'],\n",
        "    'Kurtis': ['cotton', 'silk', 'chiffon', 'georgette', 'linen', 'rayon'],\n",
        "    'Kurta Sets': ['cotton', 'silk', 'velvet', 'chanderi', 'banarasi', 'organza'],\n",
        "    'Tops': ['cotton', 'polyester', 'silk', 'lace', 'chiffon', 'viscose'],\n",
        "    'Waistcoat': ['silk', 'cotton', 'polyester', 'wool', 'blend', 'linen'],\n",
        "    'Sarees': ['silk', 'cotton', 'chiffon', 'georgette', 'linen', 'banarasi'],\n",
        "    'Night suits': ['cotton', 'satin', 'flannel', 'velvet', 'fleece', 'silk'],\n",
        "    'Shrug': ['cotton', 'polyester', 'silk', 'lace', 'chiffon', 'viscose'],\n",
        "    'Trousers': ['cotton', 'polyester', 'wool', 'blend', 'linen', 'corduroy'],\n",
        "    'Capris': ['cotton', 'polyester', 'nylon', 'spandex', 'linen', 'silk'],\n",
        "    'Jackets': ['leather', 'nylon', 'polyester', 'wool', 'blend', 'down'],\n",
        "    'Lounge Pants': ['cotton', 'fleece', 'polyester', 'silk', 'velvet', 'satin'],\n",
        "    'Tunics': ['cotton', 'silk', 'chiffon', 'georgette', 'linen', 'rayon'],\n",
        "    'Skirts': ['cotton', 'silk', 'polyester', 'wool', 'denim', 'velvet'],\n",
        "    'Tracksuits': ['polyester', 'nylon', 'cotton', 'spandex', 'fleece', 'mesh'],\n",
        "    'Swimwear': ['nylon', 'polyester', 'spandex', 'lycra', 'mesh', 'neoprene'],\n",
        "    'Jumpsuit': ['cotton', 'polyester', 'silk', 'denim', 'linen', 'spandex'],\n",
        "    'Dupatta': ['silk', 'cotton', 'chiffon', 'georgette', 'banarasi', 'velvet'],\n",
        "    'Sweaters': ['wool', 'cashmere', 'blend', 'cotton', 'polyester', 'acrylic'],\n",
        "    'unknown': ['cotton','nylon','polyester']\n",
        "}\n",
        "\n",
        "# Create a function to determine fabric based on row values\n",
        "def determine_fabric(row):\n",
        "    article_type = row['articleType']\n",
        "    if article_type in fabric_options:\n",
        "        # Example heuristic: combine certain columns to create an index\n",
        "        index = (hash(row['gender']) + hash(row['masterCategory']) +\n",
        "                 hash(row['subCategory']) + hash(row['articleType']) +\n",
        "                 hash(row['baseColour']) + hash(row['season']) +\n",
        "                 hash(row['year']) + hash(row['usage']) + hash(row['location'])) % len(fabric_options[article_type])\n",
        "        see = index\n",
        "        see2 = fabric_options[article_type][index]\n",
        "        return fabric_options[article_type][index]\n",
        "    else:\n",
        "        return 'fabric_unknown'\n",
        "\n",
        "# Apply the function to each row\n",
        "df['fabric'] = df.apply(determine_fabric, axis=1)"
      ],
      "metadata": {
        "id": "IQZtu8JcvRuG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_options = {\n",
        "    'Jeans': ['flared', 'baggy', 'loose', 'skinny', 'straight', 'bootcut'],\n",
        "    'Kurtas': ['loose', 'fitted', 'anarkali', 'straight', 'asymmetric', 'layered'],\n",
        "    'Tshirts': ['regular', 'slim', 'athletic', 'oversized', 'fitted', 'boxy'],\n",
        "    'Shirt': ['regular fit', 'slim fit', 'tailored fit', 'classic fit', 'relaxed fit', 'muscle fit'],\n",
        "    'Sweatshirts': ['relaxed', 'fitted', 'oversized', 'cropped', 'boxy', 'athletic'],\n",
        "    'Shorts': ['athletic', 'casual', 'tailored', 'cargo', 'running', 'bermuda'],\n",
        "    'Track Pants': ['comfortable', 'fitted', 'relaxed', 'slim', 'athletic', 'jogger'],\n",
        "    'Kurtis': ['loose', 'fitted', 'anarkali', 'straight', 'asymmetric', 'layered'],\n",
        "    'Kurta Sets': ['ethnic', 'traditional', 'modern', 'contemporary', 'fusion', 'festive'],\n",
        "    'Tops': ['regular', 'crop', 'off-shoulder', 'peplum', 'halterneck', 'wrap'],\n",
        "    'Waistcoat': ['formal', 'casual', 'ethnic', 'tailored', 'traditional', 'stylish'],\n",
        "    'Sarees': ['traditional', 'designer', 'bridal', 'contemporary', 'printed', 'embroidered'],\n",
        "    'Night suits': ['comfortable', 'fitted', 'oversized', 'classic', 'cozy', 'stylish'],\n",
        "    'Shrug': ['casual', 'formal', 'boho', 'cropped', 'layered', 'chic'],\n",
        "    'Trousers': ['formal', 'casual', 'tailored', 'slim', 'wide-leg', 'cropped'],\n",
        "    'Capris': ['athletic', 'casual', 'tailored', 'cropped', 'cargo', 'bermuda'],\n",
        "    'Jackets': ['fitted', 'bomber', 'oversized', 'tailored', 'biker', 'puffer'],\n",
        "    'Lounge Pants': ['comfortable', 'fitted', 'relaxed', 'cozy', 'stylish', 'athleisure'],\n",
        "    'Tunics': ['regular', 'asymmetric', 'layered', 'longline', 'boho', 'peplum'],\n",
        "    'Skirts': ['feminine', 'flared', 'pleated', 'pencil', 'maxi', 'mini'],\n",
        "    'Tracksuits': ['athletic', 'casual', 'sporty', 'cozy', 'jogger', 'stylish'],\n",
        "    'Swimwear': ['athletic', 'fitted', 'beach', 'sporty', 'high-waisted', 'bikini'],\n",
        "    'Jumpsuit': ['stylish', 'fitted', 'wide-leg', 'casual', 'tailored', 'flared'],\n",
        "    'Dupatta': ['traditional', 'embroidered', 'printed', 'designer', 'festive', 'stylish'],\n",
        "    'Sweaters': ['warm', 'cozy', 'fitted', 'oversized', 'turtleneck', 'cardigan'],\n",
        "    'Unknown Product Type': ['regular'],\n",
        "}\n",
        "\n",
        "# Create a function to determine fit based on row values\n",
        "def determine_fit(row):\n",
        "    article_type = row['articleType']\n",
        "    if article_type in fit_options:\n",
        "        # Example heuristic: combine certain columns to create an index\n",
        "        index = (hash(row['gender']) + hash(row['masterCategory']) +\n",
        "                 hash(row['subCategory']) + hash(row['articleType']) +\n",
        "                 hash(row['baseColour']) + hash(row['season']) +\n",
        "                 hash(row['year']) + hash(row['usage']) + hash(row['location']) + hash(row['fabric'])) % len(fabric_options[article_type])\n",
        "        return fabric_options[article_type][index]\n",
        "    else:\n",
        "        return 'fabric_unknown'\n",
        "\n",
        "# Apply the function to each row\n",
        "df['fit'] = df.apply(determine_fit, axis=1)\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "df.to_csv('Corelated.csv', index=False)"
      ],
      "metadata": {
        "id": "F9eQ6Q7Sve7H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning the data"
      ],
      "metadata": {
        "id": "QId7cV0Y5SLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file\n",
        "df = pd.read_csv('Corelated.csv')\n",
        "rows_to_remove = [6044, 7939, 9926, 10264, 10427, 10906, 11373, 11945, 14112, 14532, 15076, 33020, 35962, 37770, 38404]\n",
        "df = df.drop(rows_to_remove)\n",
        "df = df[df['masterCategory'] == 'Apparel']\n",
        "df.drop('id',axis=1,inplace=True)\n",
        "df.drop('productDisplayName',axis=1,inplace=True)\n",
        "df.drop('masterCategory',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "UG8XX4wRvkpA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "AfirVAWN5XhO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N61zkhX05n8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "limport pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "le_location = LabelEncoder()\n",
        "le_gender = LabelEncoder()\n",
        "\n",
        "df['location_encoded'] = le_location.fit_transform(df['location'])\n",
        "df['gender_encoded'] = le_gender.fit_transform(df['gender'])\n",
        "\n",
        "df_encoded = df.apply(LabelEncoder().fit_transform)\n",
        "\n",
        "X = df_encoded.drop(['location', 'gender', 'location_encoded'], axis=1)\n",
        "y = df_encoded['location_encoded']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "def recommend_articles(location, gender):\n",
        "    if location in le_location.classes_ and gender in le_gender.classes_:\n",
        "        location_encoded = le_location.transform([location])[0]\n",
        "        gender_encoded = le_gender.transform([gender])[0]\n",
        "        articles = df[(df['location_encoded'] == location_encoded) & (df['gender_encoded'] == gender_encoded)]\n",
        "        return articles.drop(['location', 'gender', 'location_encoded', 'gender_encoded'], axis=1)\n",
        "    else:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def recommend_articles_by_location():\n",
        "    location = input(\"Enter your location: \").strip()\n",
        "    gender = input(\"Enter your gender (Men/Women): \").strip().capitalize()\n",
        "\n",
        "    recommended_articles = recommend_articles(location, gender)\n",
        "    if not recommended_articles.empty:\n",
        "        print(recommended_articles.head())\n",
        "    else:\n",
        "        print(\"No recommendations found for the given location and gender.\")\n",
        "\n",
        "recommend_articles_by_location()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQl2Ta1YzxTA",
        "outputId": "58f3a975-0841-4dff-8f59-fa79f8f39ae5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9209911173445535\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.93       355\n",
            "           1       0.94      0.96      0.95       523\n",
            "           2       0.96      0.95      0.96       224\n",
            "           3       0.88      0.90      0.89       240\n",
            "           4       0.93      0.90      0.91       301\n",
            "           5       0.93      0.94      0.94       356\n",
            "           6       0.87      0.88      0.87       183\n",
            "           7       0.89      0.89      0.89       208\n",
            "           8       0.88      0.91      0.90       255\n",
            "           9       0.96      0.95      0.96       295\n",
            "          10       0.83      0.88      0.86       225\n",
            "          11       0.94      0.87      0.91       209\n",
            "          12       0.95      0.94      0.95       385\n",
            "          13       0.94      0.87      0.90       245\n",
            "          14       0.92      0.93      0.92       274\n",
            "\n",
            "    accuracy                           0.92      4278\n",
            "   macro avg       0.92      0.91      0.92      4278\n",
            "weighted avg       0.92      0.92      0.92      4278\n",
            "\n",
            "Enter your location: Jaipur\n",
            "Enter your gender (Men/Women): Women\n",
            "    subCategory articleType baseColour  season    year   usage     fabric  \\\n",
            "235     Topwear        Tops      Black  Summer  2012.0  Casual    chiffon   \n",
            "300     Topwear        Tops    Magenta  Summer  2012.0  Casual  polyester   \n",
            "312     Topwear      Kurtas      Cream  Summer  2012.0  Ethnic       silk   \n",
            "315     Topwear        Tops      White  Summer  2012.0  Casual  polyester   \n",
            "404     Topwear        Tops       Grey  Summer  2012.0  Casual    chiffon   \n",
            "\n",
            "        fit  \n",
            "235  cotton  \n",
            "300    silk  \n",
            "312    wool  \n",
            "315    silk  \n",
            "404  cotton  \n"
          ]
        }
      ]
    }
  ]
}